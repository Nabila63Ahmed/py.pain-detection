{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image as image_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading the models for testing\n",
    "path = '../main/'\n",
    "emotions_model = load_model(path+'model_emo_InceptionV3_nogcloud_44ep.h5')\n",
    "pain_model_adam = load_model(path+'model_pain_nogcloud_adam_120ep.h5')\n",
    "pain_model_rmsprop = load_model(path+'model_pain_nogcloud_rmsprop_240ep.h5')\n",
    "pain_model_datagen = load_model(path+'model_pain_nogcloud_datagen_240ep.h5')\n",
    "sr_model = load_model(path+'model_finalSR_3densemodel_CrossVal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_imgs_path = 'samples/'\n",
    "gray_dim = 48\n",
    "colored_dim = 160\n",
    "emotions = { 0:'Angry', 1:'Disgust', 2: 'Fear', 3: 'Happy',\n",
    "           4: 'Sad', 5: 'Surprise', 6: 'Neutral', 7: 'Pain'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PNG/JPG parse and pain detection and measurement\n",
    "\n",
    "for f in os.listdir(subfolder):\n",
    "    fileName = os.path.join(subfolder, f)\n",
    "    \n",
    "    # img to matrix\n",
    "    image = image_utils.load_img(fileName, target_size=(colored_dim, colored_dim))\n",
    "    image = image_utils.img_to_array(image).astype(np.float32)\n",
    "    image = image/ 255.\n",
    "    print(\"colored image \", filename, \" :\")\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "    # img to gray scale matrix\n",
    "    gray_image = image_utils.load_img(fileName, target_size=(gray_dim, gray_dim))\n",
    "    gray_image = image_utils.img_to_array(gray_image).astype(np.float32)\n",
    "    gray_image = gray_image/ 255.\n",
    "    gray_image = np.dot(gray_image[..., :3], [0.299, 0.587, 0.114])\n",
    "    gray_image = np.reshape(gray_image, (gray_dim, gray_dim, 1))\n",
    "    print(\"gray image \", filename, \" :\")\n",
    "    plt.imshow(gray_image)\n",
    "    plt.show()\n",
    "    \n",
    "    # emotion prediction\n",
    "    emotion_prediction = emotions_model.predict_classes(np.array([gray_image]), batch_size = 1)[0]\n",
    "    \n",
    "    print(\"predicted emotion: \", emotions[emotion_prediction])\n",
    "    \n",
    "    # If pain emotion predicted, predict its level\n",
    "    if emotion_prediction == 7 :\n",
    "        \n",
    "        painLevel_prediction = pain_model_adam.predict_classes(np.array([image]), batch_size = 1)[0]\n",
    "        \n",
    "        print(\"predicted pain level: \", painLevel_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
